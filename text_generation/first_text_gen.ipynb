{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook goes with Lesson 10, Section 10 of the Tensorflow 2.0 course on Udacity. It is a beginning look at text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-13 01:20:40--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
      "Resolving drive.google.com (drive.google.com)... 172.217.5.110, 2607:f8b0:4005:808::200e\n",
      "Connecting to drive.google.com (drive.google.com)|172.217.5.110|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7c7epsch6u4nmgvt0okpchaorf7iensm/1607822400000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2020-12-13 01:20:43--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7c7epsch6u4nmgvt0okpchaorf7iensm/1607822400000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
      "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 216.58.195.65, 2607:f8b0:4005:807::2001\n",
      "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|216.58.195.65|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/csv]\n",
      "Saving to: ‘/tmp/songdata.csv’\n",
      "\n",
      "/tmp/songdata.csv       [          <=>       ]  69.08M  21.0MB/s    in 3.3s    \n",
      "\n",
      "2020-12-13 01:20:47 (21.0 MB/s) - ‘/tmp/songdata.csv’ saved [72436445]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
    "    -O /tmp/songdata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_corpus(corpus, num_words=-1):\n",
    "    if num_words > -1:\n",
    "        tokenizer = Tokenizer(num_words = num_words)\n",
    "    else:\n",
    "        tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    return tokenizer\n",
    "\n",
    "def create_lyrics_corpus(dataset, field):\n",
    "    dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
    "    \n",
    "    dataset[field] = dataset[field].str.lower()\n",
    "    \n",
    "    lyrics = dataset[field].str.cat()\n",
    "    corpus = lyrics.split('\\n')\n",
    "    \n",
    "    for l in range(len(corpus)):\n",
    "        corpus[l] = corpus[l].rstrip()\n",
    "    \n",
    "    corpus = [l for l in corpus if l != '']\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('/tmp/songdata.csv')[:10]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'you': 1, 'i': 2, 'and': 3, 'a': 4, 'me': 5, 'the': 6, 'is': 7, 'my': 8, 'to': 9, 'ma': 10, 'it': 11, 'of': 12, 'im': 13, 'your': 14, 'love': 15, 'so': 16, 'as': 17, 'that': 18, 'in': 19, 'andante': 20, 'boomaboomerang': 21, 'make': 22, 'on': 23, 'oh': 24, 'for': 25, 'but': 26, 'new': 27, 'bang': 28, 'its': 29, 'be': 30, 'like': 31, 'know': 32, 'now': 33, 'how': 34, 'could': 35, 'youre': 36, 'sing': 37, 'never': 38, 'no': 39, 'chiquitita': 40, 'can': 41, 'we': 42, 'song': 43, 'had': 44, 'good': 45, 'youll': 46, 'she': 47, 'just': 48, 'girl': 49, 'again': 50, 'will': 51, 'take': 52, 'please': 53, 'let': 54, 'am': 55, 'eyes': 56, 'was': 57, 'always': 58, 'cassandra': 59, 'blue': 60, 'time': 61, 'dont': 62, 'were': 63, 'return': 64, 'once': 65, 'then': 66, 'sorry': 67, 'cryin': 68, 'over': 69, 'feel': 70, 'ever': 71, 'believe': 72, 'what': 73, 'do': 74, 'go': 75, 'all': 76, 'out': 77, 'think': 78, 'every': 79, 'leave': 80, 'look': 81, 'at': 82, 'way': 83, 'one': 84, 'music': 85, 'down': 86, 'our': 87, 'give': 88, 'learn': 89, 'more': 90, 'us': 91, 'would': 92, 'there': 93, 'before': 94, 'when': 95, 'with': 96, 'feeling': 97, 'play': 98, 'cause': 99, 'away': 100, 'here': 101, 'have': 102, 'yes': 103, 'baby': 104, 'get': 105, 'didnt': 106, 'see': 107, 'did': 108, 'closed': 109, 'realized': 110, 'crazy': 111, 'world': 112, 'lord': 113, 'shes': 114, 'kind': 115, 'without': 116, 'if': 117, 'touch': 118, 'strong': 119, 'making': 120, 'such': 121, 'found': 122, 'true': 123, 'stay': 124, 'together': 125, 'thought': 126, 'come': 127, 'they': 128, 'sweet': 129, 'tender': 130, 'sender': 131, 'tune': 132, 'humdehumhum': 133, 'gonna': 134, 'last': 135, 'leaving': 136, 'sleep': 137, 'only': 138, 'saw': 139, 'tell': 140, 'hes': 141, 'her': 142, 'sound': 143, 'tread': 144, 'lightly': 145, 'ground': 146, 'ill': 147, 'show': 148, 'life': 149, 'too': 150, 'used': 151, 'darling': 152, 'meant': 153, 'break': 154, 'end': 155, 'yourself': 156, 'little': 157, 'dumbedumdum': 158, 'bedumbedumdum': 159, 'youve': 160, 'dumbbedumbdumb': 161, 'bedumbbedumbdumb': 162, 'by': 163, 'theyre': 164, 'alone': 165, 'misunderstood': 166, 'day': 167, 'dawning': 168, 'some': 169, 'wanted': 170, 'none': 171, 'listen': 172, 'words': 173, 'warning': 174, 'darkest': 175, 'nights': 176, 'nobody': 177, 'knew': 178, 'fight': 179, 'caught': 180, 'really': 181, 'power': 182, 'dreams': 183, 'weave': 184, 'until': 185, 'final': 186, 'hour': 187, 'morning': 188, 'ship': 189, 'gone': 190, 'grieving': 191, 'still': 192, 'pain': 193, 'cry': 194, 'sun': 195, 'try': 196, 'face': 197, 'something': 198, 'sees': 199, 'makes': 200, 'fine': 201, 'who': 202, 'mine': 203, 'leaves': 204, 'walk': 205, 'hand': 206, 'well': 207, 'about': 208, 'things': 209, 'slow': 210, 'theres': 211, 'talk': 212, 'why': 213, 'up': 214, 'lousy': 215, 'packing': 216, 'ive': 217, 'gotta': 218, 'near': 219, 'keeping': 220, 'intention': 221, 'growing': 222, 'taking': 223, 'dimension': 224, 'even': 225, 'better': 226, 'thank': 227, 'god': 228, 'not': 229, 'somebody': 230, 'happy': 231, 'question': 232, 'smile': 233, 'mean': 234, 'much': 235, 'kisses': 236, 'around': 237, 'anywhere': 238, 'advice': 239, 'care': 240, 'use': 241, 'selfish': 242, 'tool': 243, 'fool': 244, 'showing': 245, 'boomerang': 246, 'throwing': 247, 'warm': 248, 'kiss': 249, 'surrender': 250, 'giving': 251, 'been': 252, 'door': 253, 'burning': 254, 'bridges': 255, 'being': 256, 'moving': 257, 'though': 258, 'behind': 259, 'are': 260, 'must': 261, 'sure': 262, 'stood': 263, 'hope': 264, 'this': 265, 'deny': 266, 'sad': 267, 'quiet': 268, 'truth': 269, 'heartaches': 270, 'scars': 271, 'dancing': 272, 'sky': 273, 'shining': 274, 'above': 275, 'hear': 276, 'came': 277, 'couldnt': 278, 'everything': 279, 'back': 280, 'long': 281, 'waitin': 282, 'cold': 283, 'chills': 284, 'bone': 285, 'youd': 286, 'wonderful': 287, 'means': 288, 'special': 289, 'smiles': 290, 'lucky': 291, 'fellow': 292, 'park': 293, 'holds': 294, 'squeezes': 295, 'walking': 296, 'hours': 297, 'talking': 298, 'plan': 299, 'easy': 300, 'gently': 301, 'summer': 302, 'evening': 303, 'breeze': 304, 'grow': 305, 'fingers': 306, 'soft': 307, 'light': 308, 'body': 309, 'velvet': 310, 'night': 311, 'soul': 312, 'slowly': 313, 'shimmer': 314, 'thousand': 315, 'butterflies': 316, 'float': 317, 'put': 318, 'rotten': 319, 'boy': 320, 'tough': 321, 'stuff': 322, 'saying': 323, 'need': 324, 'anymore': 325, 'enough': 326, 'standing': 327, 'creep': 328, 'felt': 329, 'cheap': 330, 'notion': 331, 'deep': 332, 'dumb': 333, 'mistake': 334, 'entitled': 335, 'another': 336, 'beg': 337, 'forgive': 338, 'an': 339, 'feels': 340, 'hoot': 341, 'holler': 342, 'mad': 343, 'under': 344, 'heel': 345, 'holy': 346, 'christ': 347, 'deal': 348, 'sick': 349, 'tired': 350, 'tedious': 351, 'ways': 352, 'aint': 353, 'walkin': 354, 'cutting': 355, 'tie': 356, 'wanna': 357, 'into': 358, 'eye': 359, 'myself': 360, 'counting': 361, 'pride': 362, 'unright': 363, 'neighbours': 364, 'ride': 365, 'burying': 366, 'past': 367, 'peace': 368, 'free': 369, 'sucker': 370, 'street': 371, 'singing': 372, 'shouting': 373, 'staying': 374, 'alive': 375, 'city': 376, 'dead': 377, 'hiding': 378, 'their': 379, 'shame': 380, 'hollow': 381, 'laughter': 382, 'while': 383, 'crying': 384, 'bed': 385, 'pity': 386, 'believed': 387, 'lost': 388, 'from': 389, 'start': 390, 'suffer': 391, 'sell': 392, 'secrets': 393, 'bargain': 394, 'playing': 395, 'smart': 396, 'aching': 397, 'hearts': 398, 'sailing': 399, 'father': 400, 'sister': 401, 'reason': 402, 'linger': 403, 'deeply': 404, 'future': 405, 'casting': 406, 'shadow': 407, 'else': 408, 'fate': 409, 'bags': 410, 'thorough': 411, 'knowing': 412, 'late': 413, 'wait': 414, 'watched': 415, 'harbor': 416, 'sunrise': 417, 'sails': 418, 'almost': 419, 'slack': 420, 'cool': 421, 'rain': 422, 'deck': 423, 'tiny': 424, 'figure': 425, 'rigid': 426, 'restrained': 427, 'filled': 428, 'whats': 429, 'wrong': 430, 'enchained': 431, 'own': 432, 'sorrow': 433, 'tomorrow': 434, 'hate': 435, 'shoulder': 436, 'best': 437, 'friend': 438, 'rely': 439, 'broken': 440, 'feather': 441, 'patch': 442, 'walls': 443, 'tumbling': 444, 'loves': 445, 'blown': 446, 'candle': 447, 'seems': 448, 'hard': 449, 'handle': 450, 'id': 451, 'thinking': 452, 'went': 453, 'house': 454, 'hardly': 455, 'guy': 456, 'closing': 457, 'front': 458, 'emptiness': 459, 'he': 460, 'disapeared': 461, 'his': 462, 'car': 463, 'stunned': 464, 'dreamed': 465, 'lifes': 466, 'part': 467, 'move': 468, 'feet': 469, 'pavement': 470, 'acted': 471, 'told': 472, 'lies': 473, 'meet': 474, 'other': 475, 'guys': 476, 'stupid': 477, 'blind': 478, 'smiled': 479, 'took': 480, 'said': 481, 'may': 482, 'couple': 483, 'men': 484, 'them': 485, 'brother': 486, 'joe': 487, 'seeing': 488, 'lot': 489, 'him': 490, 'nice': 491, 'sitting': 492, 'sittin': 493, 'memories': 494}\n",
      "495\n"
     ]
    }
   ],
   "source": [
    "corpus = create_lyrics_corpus(dataset, 'text')\n",
    "\n",
    "tokenizer = tokenize_corpus(corpus)\n",
    "\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sequences and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = max([len(seq) for seq in sequences])\n",
    "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
    "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check it out real quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "97\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29\n",
      "   4]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29   4\n",
      " 287]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index['know'])\n",
    "print(tokenizer.word_index['feeling'])\n",
    "\n",
    "print(input_sequences[5])\n",
    "print(input_sequences[6])\n",
    "\n",
    "print(one_hot_labels[5])\n",
    "print(one_hot_labels[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 6.0327 - accuracy: 0.0207\n",
      "Epoch 2/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.4555 - accuracy: 0.0368\n",
      "Epoch 3/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.3673 - accuracy: 0.0399\n",
      "Epoch 4/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.3129 - accuracy: 0.0388\n",
      "Epoch 5/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.2337 - accuracy: 0.0394\n",
      "Epoch 6/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 5.1472 - accuracy: 0.0535\n",
      "Epoch 7/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 5.0610 - accuracy: 0.0621\n",
      "Epoch 8/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.9679 - accuracy: 0.0646\n",
      "Epoch 9/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.8682 - accuracy: 0.0732\n",
      "Epoch 10/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.7650 - accuracy: 0.0797\n",
      "Epoch 11/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.6730 - accuracy: 0.0848\n",
      "Epoch 12/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.5670 - accuracy: 0.0933\n",
      "Epoch 13/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.4711 - accuracy: 0.1034\n",
      "Epoch 14/200\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 4.3700 - accuracy: 0.1206\n",
      "Epoch 15/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.2680 - accuracy: 0.1307\n",
      "Epoch 16/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 4.1703 - accuracy: 0.1438\n",
      "Epoch 17/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 4.0842 - accuracy: 0.1630\n",
      "Epoch 18/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.9922 - accuracy: 0.1680\n",
      "Epoch 19/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.8966 - accuracy: 0.1877\n",
      "Epoch 20/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.8174 - accuracy: 0.2018\n",
      "Epoch 21/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.7422 - accuracy: 0.2074\n",
      "Epoch 22/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.6581 - accuracy: 0.2185\n",
      "Epoch 23/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.5937 - accuracy: 0.2341\n",
      "Epoch 24/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.5098 - accuracy: 0.2629\n",
      "Epoch 25/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.4369 - accuracy: 0.2795\n",
      "Epoch 26/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.3780 - accuracy: 0.2886\n",
      "Epoch 27/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.3168 - accuracy: 0.3052\n",
      "Epoch 28/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.2656 - accuracy: 0.3138\n",
      "Epoch 29/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.1939 - accuracy: 0.3365\n",
      "Epoch 30/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.1282 - accuracy: 0.3542\n",
      "Epoch 31/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.0774 - accuracy: 0.3618\n",
      "Epoch 32/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.0106 - accuracy: 0.3764\n",
      "Epoch 33/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.9574 - accuracy: 0.3865\n",
      "Epoch 34/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.9006 - accuracy: 0.3996\n",
      "Epoch 35/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.8585 - accuracy: 0.4122\n",
      "Epoch 36/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.8108 - accuracy: 0.4258\n",
      "Epoch 37/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.7595 - accuracy: 0.4339\n",
      "Epoch 38/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.7209 - accuracy: 0.4490\n",
      "Epoch 39/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.6828 - accuracy: 0.4425\n",
      "Epoch 40/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.6559 - accuracy: 0.4450\n",
      "Epoch 41/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.5896 - accuracy: 0.4612\n",
      "Epoch 42/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.5625 - accuracy: 0.4627\n",
      "Epoch 43/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.5226 - accuracy: 0.4717\n",
      "Epoch 44/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.4764 - accuracy: 0.4874\n",
      "Epoch 45/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.4138 - accuracy: 0.4970\n",
      "Epoch 46/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.4067 - accuracy: 0.5015\n",
      "Epoch 47/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.3445 - accuracy: 0.5232\n",
      "Epoch 48/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.2885 - accuracy: 0.5272\n",
      "Epoch 49/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.2429 - accuracy: 0.5464\n",
      "Epoch 50/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.2027 - accuracy: 0.5489\n",
      "Epoch 51/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.1586 - accuracy: 0.5575\n",
      "Epoch 52/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.1236 - accuracy: 0.5626\n",
      "Epoch 53/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.0852 - accuracy: 0.5742\n",
      "Epoch 54/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.0562 - accuracy: 0.5721\n",
      "Epoch 55/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.0218 - accuracy: 0.5868\n",
      "Epoch 56/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.9895 - accuracy: 0.5964\n",
      "Epoch 57/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.9626 - accuracy: 0.5943\n",
      "Epoch 58/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.9249 - accuracy: 0.6039\n",
      "Epoch 59/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.8977 - accuracy: 0.6100\n",
      "Epoch 60/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.8684 - accuracy: 0.6145\n",
      "Epoch 61/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.8373 - accuracy: 0.6251\n",
      "Epoch 62/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.8227 - accuracy: 0.6282\n",
      "Epoch 63/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.7853 - accuracy: 0.6246\n",
      "Epoch 64/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.7639 - accuracy: 0.6276\n",
      "Epoch 65/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.7305 - accuracy: 0.6428\n",
      "Epoch 66/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.6856 - accuracy: 0.6468\n",
      "Epoch 67/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.6529 - accuracy: 0.6589\n",
      "Epoch 68/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.6233 - accuracy: 0.6690\n",
      "Epoch 69/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.6046 - accuracy: 0.6685\n",
      "Epoch 70/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.5996 - accuracy: 0.6655\n",
      "Epoch 71/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.5796 - accuracy: 0.6685\n",
      "Epoch 72/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.5678 - accuracy: 0.6715\n",
      "Epoch 73/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.5445 - accuracy: 0.6731\n",
      "Epoch 74/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.5067 - accuracy: 0.6932\n",
      "Epoch 75/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.5046 - accuracy: 0.6816\n",
      "Epoch 76/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.4804 - accuracy: 0.6948\n",
      "Epoch 77/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4418 - accuracy: 0.7038\n",
      "Epoch 78/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.4090 - accuracy: 0.7185\n",
      "Epoch 79/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3811 - accuracy: 0.7210\n",
      "Epoch 80/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3638 - accuracy: 0.7230\n",
      "Epoch 81/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3450 - accuracy: 0.7265\n",
      "Epoch 82/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.3263 - accuracy: 0.7296\n",
      "Epoch 83/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.3293 - accuracy: 0.7281\n",
      "Epoch 84/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.3212 - accuracy: 0.7301\n",
      "Epoch 85/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2983 - accuracy: 0.7397\n",
      "Epoch 86/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2775 - accuracy: 0.7457\n",
      "Epoch 87/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.2434 - accuracy: 0.7452\n",
      "Epoch 88/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.2173 - accuracy: 0.7614\n",
      "Epoch 89/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1990 - accuracy: 0.7619\n",
      "Epoch 90/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1956 - accuracy: 0.7598\n",
      "Epoch 91/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.1699 - accuracy: 0.7608\n",
      "Epoch 92/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1519 - accuracy: 0.7649\n",
      "Epoch 93/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.1302 - accuracy: 0.7735\n",
      "Epoch 94/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.1126 - accuracy: 0.7704\n",
      "Epoch 95/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.1028 - accuracy: 0.7760\n",
      "Epoch 96/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0883 - accuracy: 0.7841\n",
      "Epoch 97/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0768 - accuracy: 0.7785\n",
      "Epoch 98/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0678 - accuracy: 0.7765\n",
      "Epoch 99/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0501 - accuracy: 0.7810\n",
      "Epoch 100/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0278 - accuracy: 0.7901\n",
      "Epoch 101/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.0164 - accuracy: 0.7901\n",
      "Epoch 102/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0054 - accuracy: 0.7947\n",
      "Epoch 103/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.9951 - accuracy: 0.7936\n",
      "Epoch 104/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.9859 - accuracy: 0.7972\n",
      "Epoch 105/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9881 - accuracy: 0.7911\n",
      "Epoch 106/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9881 - accuracy: 0.7967\n",
      "Epoch 107/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.0062 - accuracy: 0.7861\n",
      "Epoch 108/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.9595 - accuracy: 0.7997\n",
      "Epoch 109/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9494 - accuracy: 0.7972\n",
      "Epoch 110/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.9372 - accuracy: 0.8002\n",
      "Epoch 111/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.9061 - accuracy: 0.8083\n",
      "Epoch 112/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.8912 - accuracy: 0.8143\n",
      "Epoch 113/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.8819 - accuracy: 0.8128\n",
      "Epoch 114/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.8839 - accuracy: 0.8123\n",
      "Epoch 115/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.9523 - accuracy: 0.7871\n",
      "Epoch 116/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.8961 - accuracy: 0.8042\n",
      "Epoch 117/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.8698 - accuracy: 0.8108\n",
      "Epoch 118/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.8588 - accuracy: 0.8179\n",
      "Epoch 119/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.8423 - accuracy: 0.8209\n",
      "Epoch 120/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.8290 - accuracy: 0.8224\n",
      "Epoch 121/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.8143 - accuracy: 0.8219\n",
      "Epoch 122/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.8023 - accuracy: 0.8305\n",
      "Epoch 123/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.7939 - accuracy: 0.8310\n",
      "Epoch 124/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.7860 - accuracy: 0.8300\n",
      "Epoch 125/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.7798 - accuracy: 0.8335\n",
      "Epoch 126/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.7774 - accuracy: 0.8350\n",
      "Epoch 127/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.7597 - accuracy: 0.8330\n",
      "Epoch 128/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.7570 - accuracy: 0.8375\n",
      "Epoch 129/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.7539 - accuracy: 0.8340\n",
      "Epoch 130/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.7422 - accuracy: 0.8385\n",
      "Epoch 131/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.7309 - accuracy: 0.8385\n",
      "Epoch 132/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.7201 - accuracy: 0.8370\n",
      "Epoch 133/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.7223 - accuracy: 0.8416\n",
      "Epoch 134/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.7195 - accuracy: 0.8360\n",
      "Epoch 135/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.7148 - accuracy: 0.8401\n",
      "Epoch 136/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.7016 - accuracy: 0.8426\n",
      "Epoch 137/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.6962 - accuracy: 0.8401\n",
      "Epoch 138/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.6800 - accuracy: 0.8461\n",
      "Epoch 139/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.6765 - accuracy: 0.8471\n",
      "Epoch 140/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6697 - accuracy: 0.8466\n",
      "Epoch 141/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.6698 - accuracy: 0.8441\n",
      "Epoch 142/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6643 - accuracy: 0.8502\n",
      "Epoch 143/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.6489 - accuracy: 0.8486\n",
      "Epoch 144/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.6410 - accuracy: 0.8471\n",
      "Epoch 145/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6365 - accuracy: 0.8481\n",
      "Epoch 146/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.6296 - accuracy: 0.8491\n",
      "Epoch 147/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.6226 - accuracy: 0.8547\n",
      "Epoch 148/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.6313 - accuracy: 0.8502\n",
      "Epoch 149/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.6300 - accuracy: 0.8466\n",
      "Epoch 150/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6162 - accuracy: 0.8592\n",
      "Epoch 151/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.6022 - accuracy: 0.8547\n",
      "Epoch 152/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5902 - accuracy: 0.8633\n",
      "Epoch 153/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5980 - accuracy: 0.8567\n",
      "Epoch 154/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5876 - accuracy: 0.8628\n",
      "Epoch 155/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5782 - accuracy: 0.8613\n",
      "Epoch 156/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5726 - accuracy: 0.8597\n",
      "Epoch 157/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5669 - accuracy: 0.8653\n",
      "Epoch 158/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5647 - accuracy: 0.8668\n",
      "Epoch 159/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5667 - accuracy: 0.8633\n",
      "Epoch 160/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5663 - accuracy: 0.8678\n",
      "Epoch 161/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5585 - accuracy: 0.8678\n",
      "Epoch 162/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5433 - accuracy: 0.8693\n",
      "Epoch 163/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5336 - accuracy: 0.8734\n",
      "Epoch 164/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5268 - accuracy: 0.8759\n",
      "Epoch 165/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5231 - accuracy: 0.8673\n",
      "Epoch 166/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5239 - accuracy: 0.8698\n",
      "Epoch 167/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5166 - accuracy: 0.8708\n",
      "Epoch 168/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5097 - accuracy: 0.8754\n",
      "Epoch 169/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5032 - accuracy: 0.8784\n",
      "Epoch 170/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4995 - accuracy: 0.8789\n",
      "Epoch 171/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.4933 - accuracy: 0.8824\n",
      "Epoch 172/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4873 - accuracy: 0.8779\n",
      "Epoch 173/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4821 - accuracy: 0.8804\n",
      "Epoch 174/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4774 - accuracy: 0.8829\n",
      "Epoch 175/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4731 - accuracy: 0.8865\n",
      "Epoch 176/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4695 - accuracy: 0.8850\n",
      "Epoch 177/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4698 - accuracy: 0.8870\n",
      "Epoch 178/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.4809 - accuracy: 0.8784\n",
      "Epoch 179/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.4732 - accuracy: 0.8840\n",
      "Epoch 180/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4634 - accuracy: 0.8880\n",
      "Epoch 181/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4630 - accuracy: 0.8819\n",
      "Epoch 182/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4593 - accuracy: 0.8840\n",
      "Epoch 183/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4549 - accuracy: 0.8819\n",
      "Epoch 184/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.4603 - accuracy: 0.8779\n",
      "Epoch 185/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4489 - accuracy: 0.8850\n",
      "Epoch 186/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4462 - accuracy: 0.8845\n",
      "Epoch 187/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4546 - accuracy: 0.8799\n",
      "Epoch 188/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.4497 - accuracy: 0.8835\n",
      "Epoch 189/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4432 - accuracy: 0.8819\n",
      "Epoch 190/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.4398 - accuracy: 0.8860\n",
      "Epoch 191/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4389 - accuracy: 0.8835\n",
      "Epoch 192/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4301 - accuracy: 0.8829\n",
      "Epoch 193/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4487 - accuracy: 0.8799\n",
      "Epoch 194/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4345 - accuracy: 0.8829\n",
      "Epoch 195/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.4154 - accuracy: 0.8870\n",
      "Epoch 196/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4069 - accuracy: 0.8880\n",
      "Epoch 197/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.4014 - accuracy: 0.8880\n",
      "Epoch 198/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.3954 - accuracy: 0.8920\n",
      "Epoch 199/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.3922 - accuracy: 0.8905\n",
      "Epoch 200/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.3879 - accuracy: 0.8910\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(total_words, 64, \n",
    "                              input_length=max_sequence_len-1),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
    "    tf.keras.layers.Dense(total_words, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "             loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(input_sequences, one_hot_labels, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out the Training Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(string)\n",
    "    plt.show()\n",
    "    \n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new lyrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = 'im feeling chills'\n",
    "next_words = 100\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im feeling chills me to me and you hoot and you make me strong what could and song way know feeling do found out misunderstood know feeling do do what to do you do good what could i do what could to do do what could to do be sure could to wait back could and sound you know back do what could and i do what what do what could i do what to do what could i do what could know sure to take good care didnt know do what do do what didnt know just saw what do do what\n"
     ]
    }
   ],
   "source": [
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
